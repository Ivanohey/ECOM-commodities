---
title: "sugar models"
author: "Niccol√≤ Cherubini"
date: "2023-12-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#SUGAR

for each commo: open interest sugar \~ delta price sugar t + delta price sugar t_1 + open interest t_1 + other variables t_1

```{r}
#Data splitting for sugar
library(tidyverse)
library(caret)
library(randomForest)


# Splitting the dataset in 0.7 train - 0.3 test
set.seed(42) # for reproducibility

train_indices_sugar <- sample(1:nrow(sugar_price_cot), size = 0.7 * nrow(sugar_price_cot))
train_sugar <- sugar_price_cot[train_indices_sugar, ]
test_sugar <- sugar_price_cot[-train_indices_sugar, ]

# Selecting predictor variables
predictors_sugar <- names(sugar_price_cot)[grepl(".t_1", names(sugar_price_cot))]
predictors_sugar <- setdiff(predictors_sugar, c("Cotton.t_1", "Cocoa.t_1", "Coffee.t_1", "Cotton.t", "Cocoa.t", "Coffee.t"))


```

## OPEN INTEREST

## AIC

```{r SUGAR LM AIC open interest}
#SUGAR LM

predictors_sugar_oi <- c(predictors_sugar, "Sugar.t")

#train data
train_sugar_oi <- train_sugar %>% select(all_of(c("Open_Interest.t", predictors_sugar_oi)))
train_sugar_oi <- train_sugar_oi %>% select_if(~is.numeric(.))

#test data
test_sugar_oi <- test_sugar %>% select(all_of(c("Open_Interest.t", predictors_sugar_oi)))
test_sugar_oi <- test_sugar_oi %>% select_if(~is.numeric(.))


# Linear model
sugar_lm_oi_aic <- lm(Open_Interest.t ~ ., data = train_sugar_oi)

# Stepwise model selection based on AIC
stepwise_sugar_oi <- step(sugar_lm_oi_aic, direction = "backward")

# Predict and evaluate the stepwise model
sugar_pred_oi_aic <- predict(stepwise_sugar_oi, test_sugar_oi)
mse_sugar_oi_aic <- mean((test_sugar_oi$Open_Interest.t - sugar_pred_oi_aic)^2)
r2_sugar_oi_aic <- summary(stepwise_sugar_oi)$r.squared
mae_sugar_oi_aic <- mean(abs(test_sugar_oi$Open_Interest.t - sugar_pred_oi_aic))


#Plotting predictions vs. test values
plot(sugar_pred_oi_aic ~ test_sugar_oi$Open_Interest.t, main="Sugar Open Interest AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_oi_aic~test_sugar_oi$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_sugar_oi_aic))
print(paste("MSE:", mse_sugar_oi_aic))
print(paste("R-squared:", r2_sugar_oi_aic))
print(summary(stepwise_sugar_oi))
#R-squared: 0.971484189620582
#AIC: 14517.2534706176


```

## RFE

```{r SUGAR LM RFE open interest}

# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
sugar_rfe_var_oi <- rfe(train_sugar_oi[, -which(names(train_sugar_oi) == "Open_Interest.t")], 
               train_sugar_oi$Open_Interest.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(sugar_rfe_var_oi)

sugar_oi_rfe = c("Open_Interest.t_1", "Total_Reportable_Shorts.t_1", "Total_Reportable_Longs.t_1", "Mon.t_1_Manager_Spreads.t", "Non_Reportable_Longs.t_1")

train_sugar_oi_rfe <- train_sugar_oi %>% select(all_of(c("Open_Interest.t", "Sugar.t", sugar_oi_rfe)))
test_sugar_oi_rfe <- test_sugar_oi %>% select(all_of(c("Open_Interest.t", "Sugar.t", sugar_oi_rfe)))

# Linear model
sugar_lm_oi_rfe <- lm(Open_Interest.t ~ ., data = train_sugar_oi_rfe)


# Predict and evaluate the stepwise model
sugar_pred_oi_rfe <- predict(sugar_lm_oi_rfe, test_sugar_oi_rfe)
mse_sugar_oi_rfe <- mean((test_sugar_oi_rfe$Open_Interest.t - sugar_pred_oi_rfe)^2)
r2_sugar_oi_rfe <- summary(sugar_lm_oi_rfe)$r.squared
mae_sugar_oi_rfe <- mean(abs(test_sugar_oi$Open_Interest.t - sugar_pred_oi_rfe))


#Plotting predictions vs. test values
plot(sugar_pred_oi_rfe ~ test_sugar_oi$Open_Interest.t, main="Sugar Open Interest RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_oi_rfe~test_sugar_oi$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and rfe

print(paste0("MAE: ", mae_sugar_oi_rfe))
print(paste("MSE:", mse_sugar_oi_rfe))
print(paste("R-squared:", r2_sugar_oi_rfe))
print(summary(sugar_lm_oi_rfe))

#R-squared: 0.971484189620582
#AIC: 14517.2534706176

```

## LASSO

```{r SUGAR Open Interest LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_sugar_oi <- lm(Open_Interest.t ~ ., data = train_sugar_oi)

# Calculate VIF
vif_sugar_oi_values <- vif(vif_sugar_oi)
vif_sugar_oi_table <- data.frame(Feature = names(vif_sugar_oi_values), VIF = vif_sugar_oi_values)

# Display the VIF table, sorted in descending order of VIF
vif_sugar_oi_table <- vif_sugar_oi_table %>% 
  arrange(desc(VIF)) %>% rename(`Feature Sugar` = Feature ) %>% 
  rownames_to_column() %>%  
  select(-rowname)      
print(vif_sugar_oi_table)
write_csv(vif_sugar_oi_table, "../ECOM-commodities/data/vif_sugar.csv")



# we define the target variable
target <- "Open_Interest.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_sugar_oi %>% 
  select(-Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_sugar_oi <- preProcess(train_sugar_oi[, features], method = c("center", "scale"))
sugar_train_scaled_oi <- predict(preprocess_params_sugar_oi, train_sugar_oi)
sugar_test_scaled_oi <- predict(preprocess_params_sugar_oi, test_sugar_oi)

# Train the Lasso model
set.seed(100) # for reproducibility
sugar_lasso_oi <- cv.glmnet(as.matrix(sugar_train_scaled_oi[, features]), sugar_train_scaled_oi[[target]], alpha = 1)

best_lambda <- sugar_lasso_oi$lambda.1se

# Make predictions and evaluate the model
sugar_lasso_pred_oi <- predict(sugar_lasso_oi, as.matrix(sugar_test_scaled_oi[, features]), s = "lambda.1se")
mse_sugar_lasso_oi <- mean((sugar_test_scaled_oi[[target]] - sugar_lasso_pred_oi)^2)
r2_sugar_lasso_oi <- cor(sugar_test_scaled_oi[[target]], as.vector(sugar_lasso_pred_oi))^2
mae_sugar_oi_lasso <- mean(abs(sugar_test_scaled_oi[[target]] - sugar_lasso_pred_oi))


print(paste0("MAE: ", mae_sugar_oi_lasso))

# Extract coefficients at the best lambda value
sugar_lasso_coef_oi <- coef(sugar_lasso_oi, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
sugar_lasso_coef_df_oi <- as.data.frame(as.matrix(sugar_lasso_coef_oi))

# Add row names as a new column to the data frame
sugar_lasso_coef_df_oi$feature <- rownames(sugar_lasso_coef_df_oi)

#adjusted R-Squared
n_sugar_lasso_oi <- nrow(sugar_train_scaled_oi) # number of observations
p_sugar_lasso_oi <- sum(sugar_lasso_coef_df_oi$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_sugar_lasso_oi <- 1 - ( (1 - r2_sugar_lasso_oi) * (n_sugar_lasso_oi - 1) ) / (n_sugar_lasso_oi - p_sugar_lasso_oi - 1)


# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_sugar_lasso_oi, r2 = r2_sugar_lasso_oi, adjusted_r2 = adj_r2_sugar_lasso_oi, Lambda = best_lambda, mae = mae_sugar_oi_lasso)
print(summary(sugar_lasso_oi))

# Filter out the intercept and the non-zero coefficients
sugar_lasso_selected_features_oi <- sugar_lasso_coef_df_oi[sugar_lasso_coef_df_oi$feature != "(Intercept)" & sugar_lasso_coef_df_oi$V1 != 0, ]

# Rename columns for clarity
names(sugar_lasso_selected_features_oi) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(sugar_lasso_selected_features_oi)

plot(sugar_lasso_oi)

# Calculate residuals
sugar_lasso_residuals_oi <- sugar_test_scaled_oi[[target]] - as.vector(sugar_lasso_pred_oi)

# Plot Residuals
plot(sugar_lasso_residuals_oi, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")



```

# MONEY MANAGERS

## SHORTS

### AIC

```{r}

predictors_sugar_MMS <- c(predictors_sugar, "Sugar.t")

#train data
train_sugar_MMS <- train_sugar %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", predictors_sugar_MMS)))
train_sugar_MMS <- train_sugar_MMS %>% select_if(~is.numeric(.))

#test data
test_sugar_MMS <- test_sugar %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", predictors_sugar_MMS)))
test_sugar_MMS <- test_sugar_MMS %>% select_if(~is.numeric(.))


# Linear model
sugar_lm_MMS_aic <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_sugar_MMS)

# Stepwise model selection based on AIC
stepwise_sugar_MMS <- step(sugar_lm_MMS_aic, direction = "backward")

# Predict and evaluate the stepwise model
sugar_pred_MMS_aic <- predict(stepwise_sugar_MMS, test_sugar_MMS)
mse_sugar_MMS_aic <- mean((test_sugar_MMS$Mon.t_1_Manager_Shorts.t - sugar_pred_MMS_aic)^2)
r2_sugar_MMS_aic <- summary(stepwise_sugar_MMS)$r.squared
mae_sugar_MMS_aic <- mean(abs(test_sugar_MMS$Open_Interest.t - sugar_pred_MMS_aic))


#Plotting predictions vs. test values
plot(sugar_pred_MMS_aic ~ test_sugar_MMS$Open_Interest.t, main="Sugar Money Managers Shorts AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_MMS_aic~test_sugar_MMS$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_sugar_MMS_aic))
print(paste("MSE:", mse_sugar_MMS_aic))
print(paste("R-squared:", r2_sugar_MMS_aic))
print(summary(stepwise_sugar_MMS))


```

### RFE

```{r}
# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
sugar_rfe_var_MMS <- rfe(train_sugar_MMS[, -which(names(train_sugar_MMS) == "Mon.t_1_Manager_Shorts.t")], 
               train_sugar_MMS$Mon.t_1_Manager_Shorts.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(sugar_rfe_var_MMS)

sugar_MMS_rfe = c("Mon.t_1_Manager_Shorts.t_1", "Swap_Dealer_Shorts.t_1", "Swap_Dealer_Longs.t_1", "Non_Reportable_Shorts.t_1", "Producer_Longs.t_1")


train_sugar_MMS_rfe <- train_sugar_MMS %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", "Sugar.t", sugar_MMS_rfe)))
test_sugar_MMS_rfe <- test_sugar_MMS %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", "Sugar.t", sugar_MMS_rfe)))

# Linear model
sugar_lm_MMS_rfe <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_sugar_MMS_rfe)


# Predict and evaluate the stepwise model
sugar_pred_MMS_rfe <- predict(sugar_lm_MMS_rfe, test_sugar_MMS_rfe)
mse_sugar_MMS_rfe <- mean((test_sugar_MMS_rfe$Open_Interest.t - sugar_pred_MMS_rfe)^2)
r2_sugar_MMS_rfe <- summary(sugar_lm_MMS_rfe)$r.squared
mae_sugar_MMS_rfe <- mean(abs(test_sugar_MMS$Open_Interest.t - sugar_pred_MMS_rfe))


#Plotting predictions vs. test values
plot(sugar_pred_MMS_rfe ~ test_sugar_MMS$Open_Interest.t, main="Sugar Money Managers Shorts RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_MMS_rfe~test_sugar_MMS$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and rfe

print(paste0("MAE: ", mae_sugar_MMS_rfe))
print(paste("MSE:", mse_sugar_MMS_rfe))
print(paste("R-squared:", r2_sugar_MMS_rfe))
print(summary(sugar_lm_MMS_rfe))


```

### LASSO

```{r SUGAR Money Managers Shorts LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_sugar_MMS <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_sugar_MMS)

# Calculate VIF
vif_sugar_MMS_values <- vif(vif_sugar_MMS)
vif_sugar_MMS_table <- data.frame(Feature = names(vif_sugar_MMS_values), VIF = vif_sugar_MMS_values)

# Display the VIF table, sorted in descending order of VIF
vif_sugar_MMS_table <- vif_sugar_MMS_table %>% 
  arrange(desc(VIF))
print(vif_sugar_MMS_table)


# we define the target variable
target <- "Mon.t_1_Manager_Shorts.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_sugar_MMS %>% 
  select(-Open_Interest.t_1,-Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_sugar_MMS <- preProcess(train_sugar_MMS[, features], method = c("center", "scale"))
sugar_train_scaled_MMS <- predict(preprocess_params_sugar_MMS, train_sugar_MMS)
sugar_test_scaled_MMS <- predict(preprocess_params_sugar_MMS, test_sugar_MMS)

# Train the Lasso model
set.seed(100) # for reproducibility
sugar_lasso_MMS <- cv.glmnet(as.matrix(sugar_train_scaled_MMS[, features]), sugar_train_scaled_MMS[[target]], alpha = 1)

best_lambda <- sugar_lasso_MMS$lambda.1se

# Make predictions and evaluate the model
sugar_lasso_pred_MMS <- predict(sugar_lasso_MMS, as.matrix(sugar_test_scaled_MMS[, features]), s = "lambda.1se")
mse_sugar_lasso_MMS <- mean((sugar_test_scaled_MMS[[target]] - sugar_lasso_pred_MMS)^2)
r2_sugar_lasso_MMS <- cor(sugar_test_scaled_MMS[[target]], as.vector(sugar_lasso_pred_MMS))^2
mae_sugar_MMS_lasso <- mean(abs(sugar_test_scaled_MMS[[target]] - sugar_lasso_pred_MMS))


print(paste0("MAE: ", mae_sugar_MMS_lasso))



# Extract coefficients at the best lambda value
sugar_lasso_coef_MMS <- coef(sugar_lasso_MMS, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
sugar_lasso_coef_df_MMS <- as.data.frame(as.matrix(sugar_lasso_coef_MMS))

# Add row names as a new column to the data frame
sugar_lasso_coef_df_MMS$feature <- rownames(sugar_lasso_coef_df_MMS)

#adjusted R-Squared
n_sugar_lasso_MMS <- nrow(sugar_train_scaled_MMS) # number of observations
p_sugar_lasso_MMS <- sum(sugar_lasso_coef_df_MMS$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_sugar_lasso_MMS <- 1 - ( (1 - r2_sugar_lasso_MMS) * (n_sugar_lasso_MMS - 1) ) / (n_sugar_lasso_MMS - p_sugar_lasso_MMS - 1)

# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_sugar_lasso_MMS, r2 = r2_sugar_lasso_MMS, adjusted_r2 = adj_r2_sugar_lasso_MMS, Lambda = best_lambda, mae = mae_sugar_MMS_lasso)




# Filter out the intercept and the non-zero coefficients
sugar_lasso_selected_features_MMS <- sugar_lasso_coef_df_MMS[sugar_lasso_coef_df_MMS$feature != "(Intercept)" & sugar_lasso_coef_df_MMS$V1 != 0, ]

# Rename columns for clarity
names(sugar_lasso_selected_features_MMS) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(sugar_lasso_selected_features_MMS)

plot(sugar_lasso_MMS)

# Calculate residuals
sugar_lasso_residuals_MMS <- sugar_test_scaled_MMS[[target]] - as.vector(sugar_lasso_pred_MMS)

# Plot Residuals
plot(sugar_lasso_residuals_MMS, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")






```

## LONGS

### AIC
```{r}

predictors_sugar_MML <- c(predictors_sugar, "Sugar.t")

#train data
train_sugar_MML <- train_sugar %>% select(all_of(c("Mon.t_1_Manager_Longs.t", predictors_sugar_MML)))
train_sugar_MML <- train_sugar_MML %>% select_if(~is.numeric(.))

#test data
test_sugar_MML <- test_sugar %>% select(all_of(c("Mon.t_1_Manager_Longs.t", predictors_sugar_MML)))
test_sugar_MML <- test_sugar_MML %>% select_if(~is.numeric(.))


# Linear model
sugar_lm_MML_aic <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_sugar_MML)

# Stepwise model selection based on AIC
stepwise_sugar_MML <- step(sugar_lm_MML_aic, direction = "backward")

# Predict and evaluate the stepwise model
sugar_pred_MML_aic <- predict(stepwise_sugar_MML, test_sugar_MML)
mse_sugar_MML_aic <- mean((test_sugar_MML$Mon.t_1_Manager_Shorts.t - sugar_pred_MML_aic)^2)
r2_sugar_MML_aic <- summary(stepwise_sugar_MML)$r.squared
mae_sugar_MML_aic <- mean(abs(test_sugar_MML$Open_Interest.t - sugar_pred_MML_aic))


#Plotting predictions vs. test values
plot(sugar_pred_MML_aic ~ test_sugar_MML$Open_Interest.t, main="Sugar Money Managers Longs AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_MML_aic~test_sugar_MML$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_sugar_MML_aic))
print(paste("MSE:", mse_sugar_MML_aic))
print(paste("R-squared:", r2_sugar_MML_aic))
print(summary(stepwise_sugar_MML))


```

### RFE
```{r}
# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
sugar_rfe_var_MML <- rfe(train_sugar_MML[, -which(names(train_sugar_MML) == "Mon.t_1_Manager_Longs.t")], 
               train_sugar_MML$Mon.t_1_Manager_Longs.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(sugar_rfe_var_MML)

sugar_MML_rfe = c("Mon.t_1_Manager_Longs.t_1", "Swap_Dealer_Spreads.t_1", "Non_Reportable_Longs.t_1", "Swap_Dealer_Shorts.t_1", "Sugar.t_1")

train_sugar_MML_rfe <- train_sugar_MML %>% select(all_of(c("Mon.t_1_Manager_Longs.t", "Sugar.t", sugar_MML_rfe)))
test_sugar_MML_rfe <- test_sugar_MML %>% select(all_of(c("Mon.t_1_Manager_Longs.t", "Sugar.t", sugar_MML_rfe)))

# Linear model
sugar_lm_MML_rfe <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_sugar_MML_rfe)


# Predict and evaluate the stepwise model
sugar_pred_MML_rfe <- predict(sugar_lm_MML_rfe, test_sugar_MML_rfe)
mse_sugar_MML_rfe <- mean((test_sugar_MML_rfe$Mon.t_1_Manager_Longs.t - sugar_pred_MML_rfe)^2)
r2_sugar_MML_rfe <- summary(sugar_lm_MML_rfe)$r.squared
mae_sugar_MML_rfe <- mean(abs(test_sugar_MML$Open_Interest.t - sugar_pred_MML_rfe))


#Plotting predictions vs. test values
plot(sugar_pred_MML_rfe ~ test_sugar_MML$Open_Interest.t, main="Sugar Money Managers Longs RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(sugar_pred_MML_rfe~test_sugar_MML$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and rfe

print(paste0("MAE: ", mae_sugar_MML_rfe))
print(paste("MSE:", mse_sugar_MML_rfe))
print(paste("R-squared:", r2_sugar_MML_rfe))
print(summary(sugar_lm_MML_rfe))

```


### LASSO
```{r SUGAR Money Managers Shorts LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_sugar_MML <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_sugar_MML)

# Calculate VIF
vif_sugar_MML_values <- vif(vif_sugar_MML)
vif_sugar_MML_table <- data.frame(Feature = names(vif_sugar_MML_values), VIF = vif_sugar_MML_values)

# Display the VIF table, sorted in descending order of VIF
vif_sugar_MML_table <- vif_sugar_MML_table %>% 
  arrange(desc(VIF))
print(vif_sugar_MML_table)


# we define the target variable
target <- "Mon.t_1_Manager_Longs.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_sugar_MML %>% 
 select(- Open_Interest.t_1, -Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_sugar_MML <- preProcess(train_sugar_MML[, features], method = c("center", "scale"))
sugar_train_scaled_MML <- predict(preprocess_params_sugar_MML, train_sugar_MML)
sugar_test_scaled_MML <- predict(preprocess_params_sugar_MML, test_sugar_MML)

# Train the Lasso model
set.seed(100) # for reproducibility
sugar_lasso_MML <- cv.glmnet(as.matrix(sugar_train_scaled_MML[, features]), sugar_train_scaled_MML[[target]], alpha = 1)

best_lambda <- sugar_lasso_MML$lambda.1se

# Make predictions and evaluate the model
sugar_lasso_pred_MML <- predict(sugar_lasso_MML, as.matrix(sugar_test_scaled_MML[, features]), s = "lambda.1se")
mse_sugar_lasso_MML <- mean((sugar_test_scaled_MML[[target]] - sugar_lasso_pred_MML)^2)
r2_sugar_lasso_MML <- cor(sugar_test_scaled_MML[[target]], as.vector(sugar_lasso_pred_MML))^2
mae_sugar_MML_lasso <- mean(abs(sugar_test_scaled_MML[[target]] - sugar_lasso_pred_MML))


print(paste0("MAE: ", mae_sugar_MML_lasso))

# Extract coefficients at the best lambda value
sugar_lasso_coef_MML <- coef(sugar_lasso_MML, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
sugar_lasso_coef_df_MML <- as.data.frame(as.matrix(sugar_lasso_coef_MML))

# Add row names as a new column to the data frame
sugar_lasso_coef_df_MML$feature <- rownames(sugar_lasso_coef_df_MML)

#adjusted R-Squared
n_sugar_lasso_MML <- nrow(sugar_train_scaled_MML) # number of observations
p_sugar_lasso_MML <- sum(sugar_lasso_coef_df_MML$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_sugar_lasso_MML <- 1 - ( (1 - r2_sugar_lasso_MML) * (n_sugar_lasso_MML - 1) ) / (n_sugar_lasso_MML - p_sugar_lasso_MML - 1)

# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_sugar_lasso_MML, r2 = r2_sugar_lasso_MML, adjusted_r2 = adj_r2_sugar_lasso_MML, Lambda = best_lambda, mae = mae_sugar_MML_lasso)


# Filter out the intercept and the non-zero coefficients
sugar_lasso_selected_features_MML <- sugar_lasso_coef_df_MML[sugar_lasso_coef_df_MML$feature != "(Intercept)" & sugar_lasso_coef_df_MML$V1 != 0, ]

# Rename columns for clarity
names(sugar_lasso_selected_features_MML) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(sugar_lasso_selected_features_MML)

plot(sugar_lasso_MML)

# Calculate residuals
sugar_lasso_residuals_MML <- sugar_test_scaled_MML[[target]] - as.vector(sugar_lasso_pred_MML)

# Plot Residuals
plot(sugar_lasso_residuals_MML, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")


```

```{r}
saveRDS(stepwise_sugar_oi, "models_pred/stepwise_sugar_oi.rds")
saveRDS(stepwise_sugar_MMS, "models_pred/stepwise_sugar_MMS.rds")
saveRDS(stepwise_sugar_MML, "models_pred/stepwise_sugar_MML.rds")

```
