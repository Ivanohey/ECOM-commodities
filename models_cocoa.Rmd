---
title: "models_cocoa"
author: "Niccol√≤ Cherubini"
date: "2024-01-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# COCOA

for each commo: open interest cocoa \~ delta price cocoa t + delta price cocoa t_1 + open interest t_1 + other variables t_1

```{r}
#Data splitting for cocoa
library(tidyverse)
library(caret)
library(randomForest)


# Splitting the dataset in 0.7 train - 0.3 test
set.seed(42) # for reproducibility

train_indices_cocoa <- sample(1:nrow(cocoa_price_cot), size = 0.7 * nrow(cocoa_price_cot))
train_cocoa <- cocoa_price_cot[train_indices_cocoa, ]
test_cocoa <- cocoa_price_cot[-train_indices_cocoa, ]

# Selecting predictor variables
predictors_cocoa <- names(cocoa_price_cot)[grepl(".t_1", names(cocoa_price_cot))]
predictors_cocoa <- setdiff(predictors_cocoa, c("Sugar.t_1", "Coffee.t_1", "Cotton.t_1", "Sugar.t", "Coffee.t", "Cotton.t"))


```

## OPEN INTEREST

## AIC

```{r cocoa LM AIC open interest}
#cocoa LM

predictors_cocoa_oi <- c(predictors_cocoa, "Cocoa.t")

#train data
train_cocoa_oi <- train_cocoa %>% select(all_of(c("Open_Interest.t", predictors_cocoa_oi)))
train_cocoa_oi <- train_cocoa_oi %>% select_if(~is.numeric(.))

#test data
test_cocoa_oi <- test_cocoa %>% select(all_of(c("Open_Interest.t", predictors_cocoa_oi)))
test_cocoa_oi <- test_cocoa_oi %>% select_if(~is.numeric(.))


# Linear model
cocoa_lm_oi_aic <- lm(Open_Interest.t ~ ., data = train_cocoa_oi)

# Stepwise model selection based on AIC
stepwise_cocoa_oi <- step(cocoa_lm_oi_aic, direction = "backward")

# Predict and evaluate the stepwise model
cocoa_pred_oi_aic <- predict(stepwise_cocoa_oi, test_cocoa_oi)
mse_cocoa_oi_aic <- mean((test_cocoa_oi$Open_Interest.t - cocoa_pred_oi_aic)^2)
r2_cocoa_oi_aic <- summary(stepwise_cocoa_oi)$r.squared
mae_cocoa_oi_aic <- mean(abs(test_cocoa_oi$Open_Interest.t - cocoa_pred_oi_aic))


#Plotting predictions vs. test values
plot(cocoa_pred_oi_aic ~ test_cocoa_oi$Open_Interest.t, main="Cocoa Open Interest AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_oi_aic~test_cocoa_oi$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_cocoa_oi_aic))
print(paste("MSE:", mse_cocoa_oi_aic))
print(paste("R-squared:", r2_cocoa_oi_aic))
print(summary(stepwise_cocoa_oi))

#R-squared: 0.973180108288965
#AIC: 13281.2918272419

```

## RFE

```{r cocoa LM RFE open interest}

# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
cocoa_rfe_var_oi <- rfe(train_cocoa_oi[, -which(names(train_cocoa_oi) == "Open_Interest.t")], 
               train_cocoa_oi$Open_Interest.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(cocoa_rfe_var_oi)

cocoa_oi_rfe = c("Total_Reportable_Shorts.t_1", "Open_Interest.t_1", "Total_Reportable_Longs.t_1", "Mon.t_1_Manager_Spreads.t", "Mon.t_1_Manager_Longs.t")

train_cocoa_oi_rfe <- train_cocoa_oi %>% select(all_of(c("Open_Interest.t", "Cocoa.t", cocoa_oi_rfe)))
test_cocoa_oi_rfe <- test_cocoa_oi %>% select(all_of(c("Open_Interest.t", "Cocoa.t", cocoa_oi_rfe)))

# Linear model
cocoa_lm_oi_rfe <- lm(Open_Interest.t ~ ., data = train_cocoa_oi_rfe)


# Predict and evaluate the stepwise model
cocoa_pred_oi_rfe <- predict(cocoa_lm_oi_rfe, test_cocoa_oi_rfe)
mse_cocoa_oi_rfe <- mean((test_cocoa_oi_rfe$Open_Interest.t - cocoa_pred_oi_rfe)^2)
r2_cocoa_oi_rfe <- summary(cocoa_lm_oi_rfe)$r.squared
mae_cocoa_oi_rfe <- mean(abs(test_cocoa_oi$Open_Interest.t - cocoa_pred_oi_rfe))


#Plotting predictions vs. test values
plot(cocoa_pred_oi_rfe ~ test_cocoa_oi$Open_Interest.t, main="Cocoa Open Interest RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_oi_rfe~test_cocoa_oi$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and rfe

print(paste0("MAE: ", mae_cocoa_oi_rfe))
print(paste("MSE:", mse_cocoa_oi_rfe))
print(paste("R-squared:", r2_cocoa_oi_rfe))
print(summary(cocoa_lm_oi_rfe))

#R-squared: 0.971484189620582
#AIC: 14517.2534706176

```

## LASSO

```{r cocoa Open Interest LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_cocoa_oi <- lm(Open_Interest.t ~ ., data = train_cocoa_oi)

# Calculate VIF
vif_cocoa_oi_values <- vif(vif_cocoa_oi)
vif_cocoa_oi_table <- data.frame(Feature = names(vif_cocoa_oi_values), VIF = vif_cocoa_oi_values)

# Display the VIF table, sorted in descending order of VIF
vif_cocoa_oi_table <- vif_cocoa_oi_table %>% 
  arrange(desc(VIF)) %>% rename(`Feature Cocoa` = Feature ) %>%
  rownames_to_column() %>%  
  select(-rowname)      
print(vif_cocoa_oi_table)
write_csv(vif_cocoa_oi_table, "../ECOM-commodities/data/vif_cocoa.csv")


# we define the target variable
target <- "Open_Interest.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_cocoa_oi %>% 
  select(-Open_Interest.t_1, -Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_cocoa_oi <- preProcess(train_cocoa_oi[, features], method = c("center", "scale"))
cocoa_train_scaled_oi <- predict(preprocess_params_cocoa_oi, train_cocoa_oi)
cocoa_test_scaled_oi <- predict(preprocess_params_cocoa_oi, test_cocoa_oi)

# Train the Lasso model
set.seed(100) # for reproducibility
cocoa_lasso_oi <- cv.glmnet(as.matrix(cocoa_train_scaled_oi[, features]), cocoa_train_scaled_oi[[target]], alpha = 1)

best_lambda <- cocoa_lasso_oi$lambda.1se

# Make predictions and evaluate the model
cocoa_lasso_pred_oi <- predict(cocoa_lasso_oi, as.matrix(cocoa_test_scaled_oi[, features]), s = "lambda.1se")
mse_cocoa_lasso_oi <- mean((cocoa_test_scaled_oi[[target]] - cocoa_lasso_pred_oi)^2)
r2_cocoa_lasso_oi <- cor(cocoa_test_scaled_oi[[target]], as.vector(cocoa_lasso_pred_oi))^2
mae_cocoa_oi_lasso <- mean(abs(cocoa_test_scaled_oi[[target]] - cocoa_lasso_pred_oi))

print(paste0("MAE: ", mae_cocoa_oi_lasso))

# Extract coefficients at the best lambda value
cocoa_lasso_coef_oi <- coef(cocoa_lasso_oi, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
cocoa_lasso_coef_df_oi <- as.data.frame(as.matrix(cocoa_lasso_coef_oi))

# Add row names as a new column to the data frame
cocoa_lasso_coef_df_oi$feature <- rownames(cocoa_lasso_coef_df_oi)

#adjusted R-Squared
n_cocoa_lasso_oi <- nrow(cocoa_train_scaled_oi) # number of observations
p_cocoa_lasso_oi <- sum(cocoa_lasso_coef_df_oi$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_cocoa_lasso_oi <- 1 - ( (1 - r2_cocoa_lasso_oi) * (n_cocoa_lasso_oi - 1) ) / (n_cocoa_lasso_oi - p_cocoa_lasso_oi - 1)

# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_cocoa_lasso_oi, r2 = r2_cocoa_lasso_oi, mae = mae_cocoa_oi_lasso, adjusted_r2 = adj_r2_cocoa_lasso_oi, Lambda = best_lambda)


# Filter out the intercept and the non-zero coefficients
cocoa_lasso_selected_features_oi <- cocoa_lasso_coef_df_oi[cocoa_lasso_coef_df_oi$feature != "(Intercept)" & cocoa_lasso_coef_df_oi$V1 != 0, ]

# Rename columns for clarity
names(cocoa_lasso_selected_features_oi) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(cocoa_lasso_selected_features_oi)

plot(cocoa_lasso_oi)

# Calculate residuals
cocoa_lasso_residuals_oi <- cocoa_test_scaled_oi[[target]] - as.vector(cocoa_lasso_pred_oi)

# Plot Residuals
plot(cocoa_lasso_residuals_oi, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")

# -Open_Interest.t_1, -Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1
```



# MONEY MANAGERS

## SHORTS

### AIC

```{r}

predictors_cocoa_MMS <- c(predictors_cocoa, "Cocoa.t")

#train data
train_cocoa_MMS <- train_cocoa %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", predictors_cocoa_MMS)))
train_cocoa_MMS <- train_cocoa_MMS %>% select_if(~is.numeric(.))

#test data
test_cocoa_MMS <- test_cocoa %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", predictors_cocoa_MMS)))
test_cocoa_MMS <- test_cocoa_MMS %>% select_if(~is.numeric(.))


# Linear model
cocoa_lm_MMS_aic <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_cocoa_MMS)

# Stepwise model selection based on AIC
stepwise_cocoa_MMS <- step(cocoa_lm_MMS_aic, direction = "backward")

# Predict and evaluate the stepwise model
cocoa_pred_MMS_aic <- predict(stepwise_cocoa_MMS, test_cocoa_MMS)
mse_cocoa_MMS_aic <- mean((test_cocoa_MMS$Mon.t_1_Manager_Shorts.t - cocoa_pred_MMS_aic)^2)
r2_cocoa_MMS_aic <- summary(stepwise_cocoa_MMS)$r.squared
mae_cocoa_MMS_aic <- mean(abs(test_cocoa_MMS$Open_Interest.t - cocoa_pred_MMS_aic))


#Plotting predictions vs. test values
plot(cocoa_pred_MMS_aic ~ test_cocoa_MMS$Open_Interest.t, main="Cocoa Money Managers Shorts AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_MMS_aic~test_cocoa_MMS$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_cocoa_MMS_aic))
print(paste("MSE:", mse_cocoa_MMS_aic))
print(paste("R-squared:", r2_cocoa_MMS_aic))
print(summary(stepwise_cocoa_MMS))


```

### RFE

```{r}
# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
cocoa_rfe_var_MMS <- rfe(train_cocoa_MMS[, -which(names(train_cocoa_MMS) == "Mon.t_1_Manager_Shorts.t")], 
               train_cocoa_MMS$Mon.t_1_Manager_Shorts.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(cocoa_rfe_var_MMS)

cocoa_MMS_rfe = c("Mon.t_1_Manager_Shorts.t_1", "Producer_Longs.t_1", "Swap_Dealer_Longs.t_1", "Non_Reportable_Shorts.t_1", "Other_Reportable_Longs.t_1")


train_cocoa_MMS_rfe <- train_cocoa_MMS %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", "Cocoa.t", cocoa_MMS_rfe)))
test_cocoa_MMS_rfe <- test_cocoa_MMS %>% select(all_of(c("Mon.t_1_Manager_Shorts.t", "Cocoa.t", cocoa_MMS_rfe)))

# Linear model
cocoa_lm_MMS_rfe <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_cocoa_MMS_rfe)


# Predict and evaluate the stepwise model
cocoa_pred_MMS_rfe <- predict(cocoa_lm_MMS_rfe, test_cocoa_MMS_rfe)
mse_cocoa_MMS_rfe <- mean((test_cocoa_MMS_rfe$Open_Interest.t - cocoa_pred_MMS_rfe)^2)
r2_cocoa_MMS_rfe <- summary(cocoa_lm_MMS_rfe)$r.squared
mae_cocoa_MMS_rfe <- mean(abs(test_cocoa_MMS$Open_Interest.t - cocoa_pred_MMS_rfe))


#Plotting predictions vs. test values
plot(cocoa_pred_MMS_rfe ~ test_cocoa_MMS$Open_Interest.t, main="Cocoa Money Managers Shorts RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_MMS_rfe~test_cocoa_MMS$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and rfe

print(paste0("MAE: ", mae_cocoa_MMS_rfe))
print(paste("MSE:", mse_cocoa_MMS_rfe))
print(paste("R-squared:", r2_cocoa_MMS_rfe))
print(summary(cocoa_lm_MMS_rfe))

```

### LASSO

```{r cocoa Money Managers Shorts LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_cocoa_MMS <- lm(Mon.t_1_Manager_Shorts.t ~ ., data = train_cocoa_MMS)

# Calculate VIF
vif_cocoa_MMS_values <- vif(vif_cocoa_MMS)
vif_cocoa_MMS_table <- data.frame(Feature = names(vif_cocoa_MMS_values), VIF = vif_cocoa_MMS_values)

# Display the VIF table, sorted in descending order of VIF
vif_cocoa_MMS_table <- vif_cocoa_MMS_table %>% 
  arrange(desc(VIF))
print(vif_cocoa_MMS_table)


# we define the target variable
target <- "Mon.t_1_Manager_Shorts.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_cocoa_MMS %>% 
  select(-Open_Interest.t_1, -Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_cocoa_MMS <- preProcess(train_cocoa_MMS[, features], method = c("center", "scale"))
cocoa_train_scaled_MMS <- predict(preprocess_params_cocoa_MMS, train_cocoa_MMS)
cocoa_test_scaled_MMS <- predict(preprocess_params_cocoa_MMS, test_cocoa_MMS)

# Train the Lasso model
set.seed(100) # for reproducibility
cocoa_lasso_MMS <- cv.glmnet(as.matrix(cocoa_train_scaled_MMS[, features]), cocoa_train_scaled_MMS[[target]], alpha = 1)

best_lambda <- cocoa_lasso_MMS$lambda.1se

# Make predictions and evaluate the model
cocoa_lasso_pred_MMS <- predict(cocoa_lasso_MMS, as.matrix(cocoa_test_scaled_MMS[, features]), s = "lambda.1se")
mse_cocoa_lasso_MMS <- mean((cocoa_test_scaled_MMS[[target]] - cocoa_lasso_pred_MMS)^2)
r2_cocoa_lasso_MMS <- cor(cocoa_test_scaled_MMS[[target]], as.vector(cocoa_lasso_pred_MMS))^2
mae_cocoa_MMS_lasso <- mean(abs(cocoa_test_scaled_MMS[[target]] - cocoa_lasso_pred_MMS))

print(paste0("MAE: ", mae_cocoa_MMS_lasso))



# Extract coefficients at the best lambda value
cocoa_lasso_coef_MMS <- coef(cocoa_lasso_MMS, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
cocoa_lasso_coef_df_MMS <- as.data.frame(as.matrix(cocoa_lasso_coef_MMS))

# Add row names as a new column to the data frame
cocoa_lasso_coef_df_MMS$feature <- rownames(cocoa_lasso_coef_df_MMS)

#adjusted R-Squared
n_cocoa_lasso_MMS <- nrow(cocoa_train_scaled_MMS) # number of observations
p_cocoa_lasso_MMS <- sum(cocoa_lasso_coef_df_MMS$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_cocoa_lasso_MMS <- 1 - ( (1 - r2_cocoa_lasso_MMS) * (n_cocoa_lasso_MMS - 1) ) / (n_cocoa_lasso_MMS - p_cocoa_lasso_MMS - 1)

# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_cocoa_lasso_MMS, r2 = r2_cocoa_lasso_MMS, mae = mae_cocoa_MMS_lasso, adjusted_r2 = adj_r2_cocoa_lasso_MMS, Lambda = best_lambda)




# Filter out the intercept and the non-zero coefficients
cocoa_lasso_selected_features_MMS <- cocoa_lasso_coef_df_MMS[cocoa_lasso_coef_df_MMS$feature != "(Intercept)" & cocoa_lasso_coef_df_MMS$V1 != 0, ]

# Rename columns for clarity
names(cocoa_lasso_selected_features_MMS) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(cocoa_lasso_selected_features_MMS)

plot(cocoa_lasso_MMS)

# Calculate residuals
cocoa_lasso_residuals_MMS <- cocoa_test_scaled_MMS[[target]] - as.vector(cocoa_lasso_pred_MMS)

# Plot Residuals
plot(cocoa_lasso_residuals_MMS, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")

```

## LONGS

### AIC
```{r}

predictors_cocoa_MML <- c(predictors_cocoa, "Cocoa.t")

#train data
train_cocoa_MML <- train_cocoa %>% select(all_of(c("Mon.t_1_Manager_Longs.t", predictors_cocoa_MML)))
train_cocoa_MML <- train_cocoa_MML %>% select_if(~is.numeric(.))

#test data
test_cocoa_MML <- test_cocoa %>% select(all_of(c("Mon.t_1_Manager_Longs.t", predictors_cocoa_MML)))
test_cocoa_MML <- test_cocoa_MML %>% select_if(~is.numeric(.))


# Linear model
cocoa_lm_MML_aic <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_cocoa_MML)

# Stepwise model selection based on AIC
stepwise_cocoa_MML <- step(cocoa_lm_MML_aic, direction = "backward")

# Predict and evaluate the stepwise model
cocoa_pred_MML_aic <- predict(stepwise_cocoa_MML, test_cocoa_MML)
mse_cocoa_MML_aic <- mean((test_cocoa_MML$Mon.t_1_Manager_Shorts.t - cocoa_pred_MML_aic)^2)
r2_cocoa_MML_aic <- summary(stepwise_cocoa_MML)$r.squared
mae_cocoa_MML_aic <- mean(abs(test_cocoa_MML$Open_Interest.t - cocoa_pred_MML_aic))


#Plotting predictions vs. test values
plot(cocoa_pred_MML_aic ~ test_cocoa_MML$Open_Interest.t, main="Cocoa Money Managers Longs AIC LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_MML_aic~test_cocoa_MML$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and AIC

print(paste0("MAE: ", mae_cocoa_MML_aic))
print(paste("MSE:", mse_cocoa_MML_aic))
print(paste("R-squared:", r2_cocoa_MML_aic))
print(summary(stepwise_cocoa_MML))


```

### RFE
```{r}
# Set control parameters for RFE
control <- rfeControl(functions = rfFuncs, method = "cv", number = 10)

# Running RFE with random forest model
cocoa_rfe_var_MML <- rfe(train_cocoa_MML[, -which(names(train_cocoa_MML) == "Mon.t_1_Manager_Longs.t")], 
               train_cocoa_MML$Mon.t_1_Manager_Longs.t, 
               sizes = c(1:5),  # Number of features to include
               rfeControl = control)

# View results
print(cocoa_rfe_var_MML)

cocoa_MML_rfe = c("Mon.t_1_Manager_Longs.t_1", "Producer_Shorts.t_1", "Non_Reportable_Longs.t_1", "Cocoa.t_1", "Mon.t_1_Manager_Shorts.t")


train_cocoa_MML_rfe <- train_cocoa_MML %>% select(all_of(c("Mon.t_1_Manager_Longs.t", "Cocoa.t", cocoa_MML_rfe)))
test_cocoa_MML_rfe <- test_cocoa_MML %>% select(all_of(c("Mon.t_1_Manager_Longs.t", "Cocoa.t", cocoa_MML_rfe)))

# Linear model
cocoa_lm_MML_rfe <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_cocoa_MML_rfe)


# Predict and evaluate the stepwise model
cocoa_pred_MML_rfe <- predict(cocoa_lm_MML_rfe, test_cocoa_MML_rfe)
mse_cocoa_MML_rfe <- mean((test_cocoa_MML_rfe$Mon.t_1_Manager_Longs.t - cocoa_pred_MML_rfe)^2)
r2_cocoa_MML_rfe <- summary(cocoa_lm_MML_rfe)$r.squared
mae_cocoa_MML_rfe <- mean(abs(test_cocoa_MML$Open_Interest.t - cocoa_pred_MML_rfe))


#Plotting predictions vs. test values
plot(cocoa_pred_MML_rfe ~ test_cocoa_MML$Open_Interest.t, main="Cocoa Money Managers Longs RFE LM model predicted vs. test values", xlab="Test values", ylab="Predicted values")
abline(lm(cocoa_pred_MML_rfe~test_cocoa_MML$Open_Interest.t), col="red")

# MAE, MSE, R-squared, and summary

print(paste0("MAE: ", mae_cocoa_MML_rfe))
print(paste("MSE:", mse_cocoa_MML_rfe))
print(paste("R-squared:", r2_cocoa_MML_rfe))
print(summary(cocoa_lm_MML_rfe))
```


### LASSO
```{r cocoa Money Managers Shorts LASSO Regression}
library(car)
library(readr)
library(dplyr)
library(tidyr)
library(caret)
library(glmnet)


# Calculate VIF
vif_cocoa_MML <- lm(Mon.t_1_Manager_Longs.t ~ ., data = train_cocoa_MML)

# Calculate VIF
vif_cocoa_MML_values <- vif(vif_cocoa_MML)
vif_cocoa_MML_table <- data.frame(Feature = names(vif_cocoa_MML_values), VIF = vif_cocoa_MML_values)

# Display the VIF table, sorted in descending order of VIF
vif_cocoa_MML_table <- vif_cocoa_MML_table %>% 
  arrange(desc(VIF))
print(vif_cocoa_MML_table)


# we define the target variable
target <- "Mon.t_1_Manager_Longs.t"

# we define the features that will be used in the Lasso Regression. We remove variables that are highly correlated (cf. EDA correlation heatmaps)
features <- train_cocoa_MML %>% 
  select(-Open_Interest.t_1, -Total_Reportable_Longs.t_1, -Total_Reportable_Shorts.t_1, -`Other Reportable Spreads.t_1`, - Mon.t_1_Manager_Spreads.t_1, -Producer_Shorts.t_1, -Producer_Longs.t_1) %>%
  select(-all_of(target)) %>% names()


# Scale the features
preprocess_params_cocoa_MML <- preProcess(train_cocoa_MML[, features], method = c("center", "scale"))
cocoa_train_scaled_MML <- predict(preprocess_params_cocoa_MML, train_cocoa_MML)
cocoa_test_scaled_MML <- predict(preprocess_params_cocoa_MML, test_cocoa_MML)

# Train the Lasso model
set.seed(100) # for reproducibility
cocoa_lasso_MML <- cv.glmnet(as.matrix(cocoa_train_scaled_MML[, features]), cocoa_train_scaled_MML[[target]], alpha = 1)

best_lambda <- cocoa_lasso_MML$lambda.1se

# Make predictions and evaluate the model
cocoa_lasso_pred_MML <- predict(cocoa_lasso_MML, as.matrix(cocoa_test_scaled_MML[, features]), s = "lambda.1se")
mse_cocoa_lasso_MML <- mean((cocoa_test_scaled_MML[[target]] - cocoa_lasso_pred_MML)^2)
r2_cocoa_lasso_MML <- cor(cocoa_test_scaled_MML[[target]], as.vector(cocoa_lasso_pred_MML))^2
mae_cocoa_MML_lasso <- mean(abs(cocoa_test_scaled_MML[[target]] - as.vector(cocoa_lasso_pred_MML)))

print(paste0("MAE: ", mae_cocoa_MML_lasso))

# Extract coefficients at the best lambda value
cocoa_lasso_coef_MML <- coef(cocoa_lasso_MML, s = "lambda.1se")

# Convert the sparse matrix to a regular matrix, and then to a data frame
cocoa_lasso_coef_df_MML <- as.data.frame(as.matrix(cocoa_lasso_coef_MML))

# Add row names as a new column to the data frame
cocoa_lasso_coef_df_MML$feature <- rownames(cocoa_lasso_coef_df_MML)

# adjusted R-Squared
n_cocoa_lasso_MML <- nrow(cocoa_train_scaled_MML) # number of observations
p_cocoa_lasso_MML <- sum(cocoa_lasso_coef_df_MML$V1 != 0) - 1 # number of non-zero coefficients, excluding intercept
adj_r2_cocoa_lasso_MML <- 1 - ( (1 - r2_cocoa_lasso_MML) * (n_cocoa_lasso_MML - 1) ) / (n_cocoa_lasso_MML - p_cocoa_lasso_MML - 1)

# Output the MSE, R-squared, and best lambda (alpha)
list(mse = mse_cocoa_lasso_MML, r2 = r2_cocoa_lasso_MML, mae = mae_cocoa_MML_lasso, adjusted_r2 = adj_r2_cocoa_lasso_MML, Lambda = best_lambda)


# Filter out the intercept and the non-zero coefficients
cocoa_lasso_selected_features_MML <- cocoa_lasso_coef_df_MML[cocoa_lasso_coef_df_MML$feature != "(Intercept)" & cocoa_lasso_coef_df_MML$V1 != 0, ]

# Rename columns for clarity
names(cocoa_lasso_selected_features_MML) <- c("Coefficient", "Feature")

# Print the selected features and their coefficients
print(cocoa_lasso_selected_features_MML)

plot(cocoa_lasso_MML)

# Calculate residuals
cocoa_lasso_residuals_MML <- cocoa_test_scaled_MML[[target]] - as.vector(cocoa_lasso_pred_MML)

# Plot Residuals
plot(cocoa_lasso_residuals_MML, ylab = "Residuals", xlab = "Predicted Values", main = "Residual Plot")
abline(h = 0, col = "red")

```

```{r}
saveRDS(stepwise_cocoa_oi, "models_pred/stepwise_cocoa_oi.rds")
saveRDS(stepwise_cocoa_MMS, "models_pred/stepwise_cocoa_MMS.rds")
saveRDS(stepwise_cocoa_MML, "models_pred/stepwise_cocoa_MML.rds")

```

